## ğŸ“„ Sobre este projeto

Este serviÃ§o web recebe documentos PDF, extrai o texto (usando leitura nativa quando possÃ­vel e OCR quando necessÃ¡rio), junta tudo em um Ãºnico texto e salva o resultado no Google Cloud Storage (GCS).

Em palavras simples: vocÃª aponta uma pasta com PDFs, ele lÃª tudo, transforma em texto e guarda o arquivo TXT de saÃ­da no prÃ³prio prefixo do GCS.

## ğŸ§­ Como funciona (resumo)

1. Lista os PDFs em um caminho do GCS (ex.: `gs://meu-bucket/prefixo`).
2. Para cada PDF:
	 - Tenta extrair o texto â€œnativoâ€ do PDF.
	 - Se a qualidade do texto for baixa, aplica OCR (reconhecimento de caracteres) nas pÃ¡ginas para obter o texto.
3. Concatena os textos de todos os PDFs em um Ãºnico arquivo.
4. Salva o resultado no GCS:
	- TXT concatenado no mesmo prefixo dos PDFs (`pdfs_dir`).

Tudo isso Ã© acionado por um Ãºnico endpoint HTTP (POST) que vocÃª chama com os caminhos de entrada/saÃ­da e a URL da sua API.

## ğŸ”Œ Endpoint principal

- Rota: `POST /extrator_dados_debentebtures`
- Payload (exemplo mÃ­nimo):

```
{
	"pdfs_dir": "gs://meu-bucket/entrada"
}
```

Opcionalmente, vocÃª pode ajustar alguns parÃ¢metros:
- `dpi` (padrÃ£o 300) e `lang` (`por+eng`) â€“ para o OCR
- `min_tokens`, `repeat_th`, `repeat_pages` â€“ afinam quando o OCR Ã© utilizado
- `timeout` e `retries` â€“ comportamento de rede para utilitÃ¡rios internos
 - SeleÃ§Ã£o de arquivos:
	 - `file_names`: lista de nomes exatos (ex.: ["a.pdf", "b.pdf"]).
	 - `patterns`: padrÃµes no nome, case/acento-insensitive. Se omitido e `file_names` ausente, o serviÃ§o usa defaults ["escritura", "contrato de distribuiÃ§Ã£o", "manual"].

Retorno (exemplo):

```
{
	"message": "Processamento concluÃ­do",
	"pdfs_count": 12,
	"txt_uri": "gs://meu-bucket/entrada/concat-text-20251009-163205-118.12s.txt"
}
```

## ğŸ§© O que tem â€œpor baixo dos panosâ€

- Camada de AplicaÃ§Ã£o: `src/application/pdf_processor/service.py`
	- Orquestra o fluxo: lista PDFs â†’ extrai/concatena â†’ salva TXT.
- ServiÃ§os internos: `src/infrastructure/services/`
	- `pdf_ocr.py`: leitura nativa de PDF, heurÃ­sticas e OCR (pytesseract, pdf2image, OpenCV) + utilitÃ¡rios de GCS.
    
- Rota: `src/application/extrator_dados_debenture/__init__.py`
	- ExpÃµe o endpoint oficial e aceita tanto o comportamento CRUD de exemplo quanto o payload de processamento.
- Registro de rotas: `src/routes.py`
- Bootstrap da aplicaÃ§Ã£o: `src/controller/app.py`, `main.py`
## ğŸ“„ Pipeline de PDFs (OCR + extraÃ§Ã£o)

Este serviÃ§o processa PDFs, extrai texto (nativo quando possÃ­vel e via OCR quando necessÃ¡rio), concatena tudo e grava um TXT no mesmo prefixo do GCS indicado por vocÃª.

- Entrada: um prefixo GCS com PDFs (ex.: `gs://meu-bucket/entrada`).
- SaÃ­da: um TXT concatenado salvo no mesmo prefixo (`pdfs_dir`).

Use o endpoint HTTP ou os utilitÃ¡rios Python internos descritos abaixo.

## ğŸ”Œ Endpoints

- POST `/extrator_dados_debenture`
	- Objetivo: Disparar o processamento de PDFs e obter a URI do TXT gerado.
	- Corpo (mÃ­nimo):
		```json
		{ "pdfs_dir": "gs://meu-bucket/entrada" }
		```
	- ParÃ¢metros opcionais:
		- file_names: lista de nomes exatos a processar (prioritÃ¡rio sobre patterns).
		- patterns: padrÃµes (case/acento-insensitive) para filtrar PDFs. Se omitido e file_names ausente, usa defaults ["escritura", "contrato de distribuiÃ§Ã£o", "manual"].
		- dpi (int, padrÃ£o 300), lang (str, padrÃ£o "por+eng"): ajustes do OCR.
		- min_tokens (int, padrÃ£o 120), repeat_th (float, padrÃ£o 0.30), repeat_pages (float, padrÃ£o 0.6): heurÃ­sticas de decisÃ£o entre extraÃ§Ã£o nativa e OCR.
		- timeout, retries: parÃ¢metros gerais (nÃ£o crÃ­ticos apÃ³s remoÃ§Ã£o da API externa).
	- Resposta (200):
		```json
		{
			"message": "Processamento concluÃ­do",
			"pdfs_count": 3,
			"txt_uri": "gs://meu-bucket/entrada/concat-text-20251009-163205-118.12s.txt"
		}
		```

Exemplo rÃ¡pido com curl:
```bash
curl -X POST http://localhost:8000/extrator_dados_debenture \
	-H 'Content-Type: application/json' \
	-d '{"pdfs_dir":"gs://meu-bucket/entrada"}'
```

## ğŸ§  Como funciona

1. Lista PDFs no `pdfs_dir` (GCS) usando:
	 - nomes exatos (file_names), ou
	 - padrÃµes (patterns), ou
	 - padrÃµes default ["escritura", "contrato de distribuiÃ§Ã£o", "manual"].
2. Para cada PDF:
	 - Extrai texto nativo com PyPDF2; mede qualidade com heurÃ­sticas.
	 - Se a qualidade for baixa, aplica OCR (pytesseract + pdf2image + OpenCV).
3. Concatena tudo e grava um TXT em `pdfs_dir`.

CÃ³digo principal: `src/application/pdf_processor/service.py`.

## ğŸ§© UtilitÃ¡rios internos (Python)

MÃ³dulo: `src/infrastructure/services/pdf_ocr.py`

- GCS e seleÃ§Ã£o de arquivos
	- `is_gcs_uri(s: str) -> bool`: verifica `gs://`.
	- `parse_gcs_uri(uri: str) -> tuple[bucket, prefix]`: separa bucket/prefix.
	- `gcs_list_pdfs(dir_uri: str, recursive=True, file_names=None) -> list[str]`: lista PDFs no GCS; filtra por nome se informado.
	- `gcs_read_bytes(gs_path: str) -> bytes`: baixa bytes de um arquivo no GCS.
	- `gcs_write_text(dir_uri: str, filename: str, text: str) -> str`: grava TXT em `dir_uri/filename`.
	- `find_pdfs_by_patterns(root_dir: str, patterns: list[str], recursive=True) -> list[str]`: filtra por padrÃµes no nome (GCS ou local para utilidade).

- ExtraÃ§Ã£o de texto
	- `load_pdf_bytes(identifier: str) -> bytes`: lÃª bytes de `gs://...` ou caminho local.
	- `extract_native_per_page_from_bytes(pdf_bytes: bytes) -> list[str]`: texto nativo por pÃ¡gina (PyPDF2).
	- `extract_text(pdf_identifier: str, dpi: int, lang: str, min_tokens: int, repeat_th: float, repeat_pages_frac: float) -> str`:
		aplica heurÃ­sticas e decide entre nativo e OCR, retornando o texto com cabeÃ§alhos por pÃ¡gina.
	- `concat_many_pdfs_to_text(pdf_identifiers: list[str], dpi: int, lang: str, min_tokens: int, repeat_th: float, repeat_pages_frac: float) -> str`:
		processa vÃ¡rios PDFs e concatena em um Ãºnico texto legÃ­vel.

- HeurÃ­sticas de qualidade (principais)
	- `tokenize`, `avg_tokens_per_page`, `normalize_line`, `repetition_coverage`.
	- `text_quality_metrics`: calcula mÃ©tricas (printable, alnum, mean word len, etc.).
	- `should_force_ocr(pages, min_tokens, repeat_threshold, repeat_pages_frac) -> (bool, float, float)`:
		retorna se deve forÃ§ar OCR e mÃ©tricas auxiliares (avg tokens, repetiÃ§Ã£o).

ObservaÃ§Ã£o: funÃ§Ãµes internas de prÃ©-processamento de imagem (`_deskew`, `_preprocess`, `_choose_psm`) sÃ£o detalhes da implementaÃ§Ã£o e podem mudar.

## â–¶ï¸ Rodando o serviÃ§o

Local (Python 3.11+):
- Instale dependÃªncias: `pip install -r requirements.txt`
- Exporte credenciais GCP (se necessÃ¡rio): `GOOGLE_APPLICATION_CREDENTIALS=/caminho/key.json`
- Inicie: `python main.py`

Docker (recomendado):
- Build: `docker build -t chassi -f docker/Dockerfile .`
- Run: `docker run -p 8000:8000 -e GOOGLE_APPLICATION_CREDENTIALS=/secrets/key.json -v /abs/key.json:/secrets/key.json chassi`

## ğŸ” VariÃ¡veis de ambiente

- `HOST`, `PORT`, `SERVER_ROOT`: parÃ¢metros do servidor.
- `GOOGLE_APPLICATION_CREDENTIALS`: caminho para credenciais do GCS.

## ğŸ§ª Testes

- `make devdeps` e `make unit-tests`
- Os testes cobrem o orquestrador e utilitÃ¡rios de OCR; chamadas pesadas sÃ£o mockadas.

## ğŸ› ï¸ SoluÃ§Ã£o de problemas

- Tesseract/Poppler nÃ£o encontrados: prefira a imagem Docker (jÃ¡ provisiona ambos).
- Acesso ao GCS falhou: verifique `GOOGLE_APPLICATION_CREDENTIALS` e permissÃµes.

## ğŸ—‚ï¸ Estrutura

- `src/application/pdf_processor/` â€” Orquestra o processamento.
- `src/infrastructure/services/` â€” OCR e utilitÃ¡rios GCS.
- `src/application/extrator_dados_debenture/` â€” Endpoint e CRUD de exemplo.
- `src/routes.py` â€” Registro de rotas.
- `docker/Dockerfile` â€” Imagem com OCR.
- `requirements*.txt` â€” DependÃªncias.

â€”
Se quiser estender para gerar tambÃ©m um JSON de metadados (p.ex., PDFs processados e estatÃ­sticas), dÃ¡ para salvar um `summary.json` no mesmo `pdfs_dir`. Posso incluir isso sob demanda.